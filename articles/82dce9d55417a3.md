---
title: "2項演算子の優先度と結合性だけで作るパーサ"
emoji: "🗂"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["rust", "自作言語", "プログラミング言語", "パーサ"]
published: false
---
「Rustで作るプログラミング言語」関連のトピック、第2弾です。

[前回](https://zenn.dev/msakuta/articles/7f1bf1fc92aefb)は Rustack の話題でしたが、今回は Ruscal の構文解析の中で紹介できなかったトピックです。

本書では再帰下降パーサを構文解析に使っていますが、再帰下降パーサには複数のマッチする構文の候補を繰り返し適用し、失敗したらバックトラックするという無駄があります。これは現代のCPUでは現実的な問題になることは少ないと思いますが、最適化できる無駄であることは事実です。本稿では2項演算子に特化した最適化手法である Precedence climbing method について紹介したいと思います[^1]。

この手法は、一つのパーサを書くだけでいかなる2項演算の優先順位や結合性の組み合わせでも対応できるという利点がありますが、さらに、演算子の実行時カスタマイズも可能になります。これは、例えば Haskell のようにユーザー定義の演算子に好きな優先順位や結合性を定義できる言語で役に立ちます。

[^1]: この他にも、メモ化(Memoization)を利用した Packrat parsing や、字句解析と構文解析のステップを分けるなどのさまざまな最適化手法があります。

[Wikipedia](https://en.wikipedia.org/wiki/Operator-precedence_parser#Precedence_climbing_method) には疑似コードが載っているのですが、これがえらく抽象的で読みにくく、これを動作する Rust コードに書き換えるのに難儀しました。

最終的には、[こちら](https://gist.github.com/msakuta/b22bc0950b1efe6c7a8560434a7835a2)に置いたようなコートで実現しました。

# 優先度を辿るコード

肝となるのは次の `bin_op` 関数です。優先度を示す `prec: usize` を引数に取り、パーサ関数を返す高階関数となっていますが、これは nom を使ってパーサコンビネータに組み込むことを目論んでのことです[^2]。しかしながら、実際のコードでは結局高階関数としての使い方はしませんでした。

[^2]: 例えば、2項演算の式をセミコロンで区切る文とするなら、 `terminated(bin_op(prec), tag(";"))` といったコンビネータの使い方ができるはずです。

```rust
fn bin_op<'src>(
    prec: usize,
) -> impl Fn(Lexer<'src>) -> Option<(Lexer<'src>, Expression<'src>)> + 'src {
    use std::convert::TryInto;
    move |mut lexer: Lexer| {
        let (next, mut ret) = term(lexer)?;
        lexer = next;
        let Some(mut lookahead) = lexer.peek() else {
            return Some((lexer, ret));
        };
        while let Token::Op(op) = lookahead {
            if precedence(&op) < prec {
                break;
            }
            lexer.next()?;
            let inner_next = lexer;
            let (outer_next, rhs) = term(lexer)?;
            lexer = outer_next;
            let mut rhs: Expression = rhs.try_into().ok()?;
            let Some(p_lookahead) = lexer.peek() else {
                return Some((lexer, Expression::bin_op(op, ret, rhs)));
            };
            lookahead = p_lookahead;

            while let Token::Op(next_op) = lookahead {
                if precedence(&next_op) <= precedence(&op)
                    && (precedence(&next_op) != precedence(&op)
                        || associativity(&op) != Associativity::Right)
                {
                    break;
                }
                let next_prec = precedence(&op)
                    + if precedence(&op) < precedence(&next_op) {
                        1
                    } else {
                        0
                    };
                (lexer, rhs) = bin_op(next_prec)(inner_next)?;
                let Some(p_lookahead) = lexer.peek() else {
                    return Some((lexer, Expression::bin_op(op, ret, rhs)));
                };
                lookahead = p_lookahead;
            }
            ret = Expression::bin_op(op, ret, rhs);
        }

        Some((lexer, ret))
    }
}
```

一目見て思うのは、**やたら長い**ということではないでしょうか。これにはいくつか理由があります。まず、 Precedence climbing method は2重のループを持つので、パーサコンビネータを使った構文解析で見かける普通の関数よりも長くなりがちです。もう一つは、トークンの先読みを必要とするので、入力ソースが字句解析済みだという前提であることです。字句解析器は Lexical analyzer を略して `Lexer` という型に抽象化していますが、それでも長いです。さらに、無駄に高階関数にしようとして `move` したラムダを返していますが、これも複雑度を増しています(これはせいぜい3行程度ですが)。

それでも、全ての2項演算子に使いまわせるという点は利点です。

## 字句解析器 `Lexer`

`Lexer` の実体はただの文字列スライスです。本来はトークンの配列などに一度変換すれば、先読みから戻ってきたときの手戻りがなくなるとは思いますが、2項演算以外にも構文が存在するので、全ての構文要素にトークン化を施す必要があり、影響範囲が大きくなります。

```rust
#[derive(Clone, Copy, Debug, PartialEq, Eq)]
struct Lexer<'src> {
    cur: &'src str,
}
```

`Lexer` には、トークンを切り出したうえで自分自身を次のトークンへ前進させる `next` というメソッドと、自分自身を変更させずに次のトークンを返す `peek` というメソッドを持ちます。
それぞれの実装は下記のとおりです。

```rust
impl<'src> Lexer<'src> {
    fn next(&mut self) -> Option<Token<'src>> {
        if let Some((r, res)) = token(self.cur) {
            self.cur = r;
            return Some(res);
        }
        None
    }

    fn peek(&self) -> Option<Token<'src>> {
        if let Some((_, res)) = token(self.cur) {
            return Some(res);
        }
        None
    }
}
```

`token` という関数は、文字列スライスを入力に取り、入力の残りと認識したトークンを返す次のようなもので、 nom のコンビネータと互換性を持たせています。

```rust
fn token(input: &str) -> Option<(&str, Token)> {
    if let Some(r) = lparen(whitespace(input)) {
        return Some((r, Token::LParen));
    }
    if let Some(r) = rparen(whitespace(input)) {
        return Some((r, Token::RParen));
    }
    if let Some(res) = ident(whitespace(input)) {
        return Some(res);
    }
    if let Some(res) = number(whitespace(input)) {
        return Some(res);
    }
    if let Some(res) = operator(whitespace(input)) {
        return Some(res);
    }
    None
}
```



## 演算子の種類と優先順位と結合性の定義

では、どうやって2項演算子の種類と優先順位と結合性を区別するのでしょうか。それは別途定義した `OpCode` 列挙子で決まります。

```rust
#[derive(Debug, PartialEq, Clone, Copy)]
enum OpCode {
    Add,
    Sub,
    Mul,
    Div,
}
```

これは字句解析器が出力するトークンの一種になります。トークン自体は次のような列挙にしておきます。

```rust
#[derive(Debug, PartialEq, Clone, Copy)]
enum Token<'src> {
    Ident(&'src str),
    NumLiteral(f64),
    Op(OpCode),
    LParen,
    RParen,
}
```

演算子の字句解析は次のようなロジックになります。まだ一文字の演算子だけなので簡単です。

```rust
fn operator(input: &str) -> Option<(&str, Token)> {
    match peek_char(input) {
        Some('+') => Some((advance_char(input), Token::Op(OpCode::Add))),
        Some('-') => Some((advance_char(input), Token::Op(OpCode::Sub))),
        Some('*') => Some((advance_char(input), Token::Op(OpCode::Mul))),
        Some('/') => Some((advance_char(input), Token::Op(OpCode::Div))),
        _ => None,
    }
}
```

演算子の優先度は次のように関数で定義しておきます。

```rust
fn precedence(op: &OpCode) -> usize {
    match op {
        OpCode::Add => 1,
        OpCode::Sub => 1,
        OpCode::Mul => 2,
        OpCode::Div => 2,
    }
}
```

結合性は今のところ左結合しかありませんので、次のような定数関数になります。

```rust
#[derive(Clone, Copy, PartialEq, Eq)]
enum Associativity {
    Left,
    Right,
}

fn associativity(_op: &OpCode) -> Associativity {
    Associativity::Left
}
```

## 式 (`Expression`) の修正

式 (`Expression`) は Ruscal の定義と似ていますが、任意の2項演算子を構文木のノードとして持てるようにするため、 `BinOp` バリアントの定義が `OpCode` を引数として持つようになります。

```rust
#[derive(Debug, PartialEq)]
enum Expression<'src> {
    Ident(&'src str),
    NumLiteral(f64),
    BinOp {
        op: OpCode,
        lhs: Box<Expression<'src>>,
        rhs: Box<Expression<'src>>,
    },
}
```

また、トークンは構文木の葉になるはずですので(構文解析の世界では終端記号とも呼ばれます)、この変換を行う `TryFrom` トレイトを実装しておきます。 `From` トレイトにしない理由は、全てのトークンが葉になるわけではないからです。例えば `+` や `-` といったトークンは2項演算のノードになりますが、葉にはなりませんので、変換は失敗します。

```rust
impl<'src> TryFrom<Token<'src>> for Expression<'src> {
    type Error = ();
    fn try_from(value: Token<'src>) -> Result<Self, Self::Error> {
        match value {
            Token::Ident(id) => Ok(Expression::Ident(id)),
            Token::NumLiteral(num) => Ok(Expression::NumLiteral(num)),
            _ => Err(()),
        }
    }
}
```



## エントリポイントとテスト

式のエントリポイントとなる全体のパーサは次のようになります。 `bin_op` を最低優先度 0 で呼び出しているところが肝です。

```rust
fn expr(lexer: Lexer) -> Option<(Lexer, Expression)> {
    if let Some(res) = bin_op(0)(lexer) {
        return Some(res);
    }

    None
}
```

いくつかの式の例でテストしてみましょう。まずは次のようなテスト用のヘルパー関数を用意しておきます。

```rust
fn test_case(input: &str) {
    let lexer = Lexer::new(input);
    match expr(lexer) {
        Some((_, res)) => {
            println!("source: {:?}, parsed: {}", input, res);
        }
        _ => {
            println!("source: {input:?}, failed");
        }
    }
}
```

また、式を `Debug` トレイトの実装で出力すると、余計な情報が多くて非常に見にくいので、簡潔にフォーマットする `Display` トレイトの実装をしておきます。

```rust
impl<'src> std::fmt::Display for Expression<'src> {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::Ident(id) => write!(f, "{id}"),
            Self::NumLiteral(num) => write!(f, "{num}"),
            Self::BinOp { op, lhs, rhs } => {
                write!(f, "(")?;
                lhs.fmt(f)?;
                write!(f, " {op} ")?;
                rhs.fmt(f)?;
                write!(f, ")")
            }
        }
    }
}
```

これで次のようにテストしてみます。

```rust
fn main() {
    let args = std::env::args();
    for arg in args {
        if arg == "-d" {
            DEBUG.store(true, std::sync::atomic::Ordering::Relaxed);
        }
    }
    test_case("123");
    test_case("Hello + world");
    test_case("1 * 3");
    test_case("1 + 2 + 3");
    test_case("1 - 2 + 3");
    test_case("10 + 1 * 3");
    test_case("10 * 1 + 3");
    test_case("10 + 1 * 3 + 100");
    test_case("9 / 3 / 3");
    test_case("(123 + 456 ) + world");
    test_case("car + cdr + cdr");
    test_case("((1 + 2) + (3 + 4)) + 5 + 6 * 7");
}
```

結果は次のように出力されます。入力に明示的に括弧がついて優先順位が明確になったような出力で、合っていることは容易に見て取れます。

```
source: "123", parsed: 123
source: "Hello + world", parsed: (Hello + world)
source: "1 * 3", parsed: (1 * 3)
source: "1 + 2 + 3", parsed: ((1 + 2) + 3)
source: "1 - 2 + 3", parsed: ((1 - 2) + 3)
source: "10 + 1 * 3", parsed: (10 + (1 * 3))
source: "10 * 1 + 3", parsed: ((10 * 1) + 3)
source: "10 + 1 * 3 + 100", parsed: ((10 + (1 * 3)) + 100)
source: "9 / 3 / 3", parsed: ((9 / 3) / 3)
source: "(123 + 456 ) + world", parsed: ((123 + 456) + world)
source: "car + cdr + cdr", parsed: ((car + cdr) + cdr)
source: "((1 + 2) + (3 + 4)) + 5 + 6 * 7", parsed: ((((1 + 2) + (3 + 4)) + 5) + (6 * 7))
```
